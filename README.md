# Pernicious Energy Attack using Reinforcement Learning (PEARL)
False data injection (FDI) in smart home sensor measurements can incur increased energy costs and compromise inhabitants' health status. Researchers are developing machine learning (ML)-based efficient anomaly detection models (ADMs) to blend detection-based solid defense strategies into smart home control systems. However, an adversary with adequate system knowledge and computational power can identify backdoors from the control model and ADMs to carry out stealthy FDI attacks. Hence, modern ADMs are assessed against stealthy FDI attacks instead of random attacks for realistic security and robustness analysis. Nevertheless, identifying the stealthy attack vectors from ML-based non-linear ADMs is yet to be contemplated. The state-of-the-art (SOTA) attack analytics leverages formal attack synthesis, which linearizes such ADMs to extract attack vectors from the massive computational complexity. Nevertheless, the linearization effort diminishes significant details of the actual ADMs, preventing identifying a range of critical attack vectors that can create a significant impact. Moreover, the adoption of window-based optimization allows the SOTA formal analysis frameworks to extract only those attack vectors, where the attacker has measurement access throughout the day, which further reduces the potential to identify critical threats. We propose a novel reinforcement learning-based framework, PEARL, to identify stealthy attack vectors from a non-linear ADM-supported smart home control system, which deals with the limitations of SOTA analytics. We validate our framework using the SOTA Activity Recognition with Ambient Sensing dataset.
